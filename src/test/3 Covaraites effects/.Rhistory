clusters = salso_out[1:105]
)
df_temp$Time = rep(time,dim(df_temp)[1])
df_cluster = rbind(df_cluster,df_temp)
# clusters log
clusters_now = df_temp$clusters
n_clusters = unique(clusters_now)
ycurrent = y[,paste0("w",time)]
cat(crayon::red("Time",time,"- #clusters =",length(unique(clusters_now)),"\n"))
}
clusters_old = NULL
for(time in time_span[1:limt]){
cat(crayon::red("Time",time,"of",Tm,"\n"))
df_cluster_cut = df_cluster[df_cluster$Time==time,]
clusters_now = df_cluster_cut$clusters
####### no mode correct now
# clusters_now = mode_correct_clusters(clusters_old,clusters_now,very_verbose = 0)
# se fai heat plot non serve fare la mode correct
# perché la heat plot la usi per vedere anche i valori di pm10, non la coerenza temporale
# nei gruppi, che con la heat coloration si perde come visibilità (non so se è chiaro)
df_cluster_cut$clusters = clusters_now
# meglio l'idea 1
cols = color_correct_clusters(df_cluster_cut,idea=1,verbose=0)
cur_num = sprintf("%02d", time)
plot1 <- get_graph_plot(df_cluster_cut,cols,titolo=paste0(model_name," - time ",time))
covariata = "AQ_pm10"
plot2 = get_boxplot_covariate_plot(df_cluster_cut,cols,titolo=covariata,
covariata = covariata,annotate = F)
# covariata = "Altitude"
covariata = "WE_wind_speed_10m_max"
plot3 = get_boxplot_covariate_plot(df_cluster_cut,cols,titolo=covariata,
covariata = covariata,annotate = F)
# covariata = "LA_lvi"
covariata = "WE_tot_precipitation"
plot4 = get_boxplot_covariate_plot(df_cluster_cut,cols,titolo=covariata,
covariata = covariata,annotate = F)
# covariata = "WE_tot_precipitation"
covariata = "WE_blh_layer_max"
plot5 = get_boxplot_covariate_plot(df_cluster_cut,cols,titolo=covariata,
covariata = covariata,annotate = F)
g <- arrangeGrob(
plot1, plot2, plot3, plot4, plot5,
widths = c(2, 1, 1),
layout_matrix = rbind(c(1, 2, 3),
c(1, 4, 5)))
if (save_plot==TRUE){
dir.create(paste0(folder,"layout_small"))
ggsave(file=paste0(folder,"layout_small/",model_name,"_t",cur_num,".pdf"),plot = g,
# units="px",width=2500, height=1200, dpi=300)
# units="px",width=4500, height=2000, dpi=300)
units="px",width=3600, height=1500, dpi=300)
# units="px",width=2880, height=1200, dpi=300)
dev.off()
} else {
print(g)
}
clusters_old = clusters_now
}
citation()
load("../thesis data/df_wsc.Rdata")
# load("../thesis data/df_daily_full.Rdata")
# df_wsc = df_daily_full
# load("../thesis data/df_daily_full_logtransf.Rdata")
# df_wsc = df_daily_full_logtransf
# df_wsc$IDStations[which(df_wsc$IDStations=="STA-CH0011A")] = "STA.CH0011A"
# df_wsc$IDStations[which(df_wsc$IDStations=="STA-CH0033A")] = "STA.CH0033A"
# df_wsc$IDStations[which(df_wsc$IDStations=="STA-CH0043A")] = "STA.CH0043A"
unique(df_wsc$IDStations)
na_summary(df_wsc)
sites_full = data.frame(
longitude = unique(df_wsc$Longitude),
latitude = unique(df_wsc$Latitude))
stations = unique(df_wsc$IDStations)
yfull=data.frame()
target = "AQ_pm10"
for(st in stations){
y_we_pm10=cbind(as.data.frame(st),t(df_wsc[which(df_wsc$IDStations==st),target]))
yfull=rbind(yfull,y_we_pm10)
}
rownames(yfull) = NULL
colnames(yfull)<- c("id",paste0("w", 1:(size(yfull)[2]-1)))
# time_span = 1:14 # GOOD
# time_span = 1:4
time_span = 1:12
set.seed(110)
# quanti = 80; nsubjects = sample(1:105, quanti,replace = F)
# quanti = 30; nsubjects = sample(1:105, quanti,replace = F) #GOOD
# quanti = 60; nsubjects = sample(1:105, quanti,replace = F)
nsubjects = 1:105
# nsubjects = 1:10
y = yfull[nsubjects,1+time_span]
#############################################
# authors suggested to/did scale the spatial locations and also centered the observations
mn <- apply(y,2,mean)
sd <- apply(y,2,sd)
y <- t(t(y) - mn)
# y <- t(t(y) - mn)+1 # shifted 1
Tm = tps <- ncol(y) # time span
N = size(y)[1] # number of units
num_units = N
sites = sites_full[nsubjects,]
smn <- apply(sites,2,mean)
ssd <- apply(sites,2,sd)
s_std <- t((t(sites) - smn)/ssd)
# check
# mean(s_std[,1])
# mean(s_std[,2])
# var(s_std[,2])
# var(s_std[,1])
######################################
# yred=(y[,time_span]+0.5)*2
yred=y
par(mar=c(2,2,2,1))
# par(mar=c(4,4,2,2))
cols = colora(size(yred)[1],56,0)
for(i in 1:size(yred)[1]){
if(i==1){
plot(1:size(yred)[2],yred[i,],col=cols[i],
# ylim=extrema(as.matrix(yred[,-c(1)])),
ylim=extrema(as.matrix(yred)),
type='l',xlab='weeks',ylab='pm10')
}
else{
lines(1:size(yred)[2],yred[i,],col=cols[i])
}
}
# for(i in 1:N){
# 	text(1,yred[i,1],i,cex=0.7)
# }
# -> we have
# y = yred
y
s_std
plot(s_std)
rownames(s_std) = NULL
ranked_indices = c(1:n) # per dopo
# as.integer(runif(1,0,1000))*1.0
seed = 888.0
# seed = 314.0
cat("seed",seed,"\n")
set.seed(seed)
# niter=10000; nburn=6000; nthin=4
# niter=50000; nburn=10000; nthin=40 # they did this in their tests
# niter=10000; nburn=0; nthin=1
# niter=20000; nburn=15000; nthin=5
# niter=50000; nburn=30000; nthin=20 # GOOD
# niter=80000; nburn=60000; nthin=20
niter=110000; nburn=90000; nthin=5
# niter=100000; nburn=60000; nthin=40
# niter=100; nburn=0; nthin=1
nout <- (niter-nburn)/nthin
cat(nout,"valid iterations\n")
niter = as.integer(niter)
nburn = as.integer(nburn)
nthin = as.integer(nthin)
# params
m0_phi0 = 0
# s20_phi0 = 8
# A_ub_sigma = 7
s20_phi0 = 10
A_ub_sigma = 5
A_ub_tau = 5
A_ub_lambda = 5
# a_sigma  = 3; b_sigma  = 4
# a_tau    = 3; b_tau    = 4
# a_lambda = 3; b_lambda = 4
# a_sigma  = 2; b_sigma  = 2
# a_tau    = 2; b_tau    = 2
# a_lambda = 2; b_lambda = 2
a_sigma  = 0.01; b_sigma  = 0.01
a_lambda = 0.1; b_lambda = 0.1
# # a_tau    = 0.1; b_tau    = 0.1
a_tau    = 2; b_tau    = 2
# a_tau    = 1; b_tau    = 1.5
# a_sigma  = 5; b_sigma  = 8
# a_tau    = 5; b_tau    = 8
# a_lambda = 5; b_lambda = 8
eta1_scale = 0.9
# mh is the of gaussian standard deviations for metropolis updates
# So these are not variances!
sig_mh_sig2 = 0.2
sig_mh_tau2 = 0.2
sig_mh_lambda2 = 0.2
sig_mh_eta1 = 0.2
sig_mh_phi1 = 0.2
update_eta1 = TRUE
update_phi1 = F
a_alpha = 2; b_alpha = 2
time_specific_alpha = TRUE
# now space
spatial_cohesion = 3
mu0 = 0
k0 = 1
v0 = 5
L0 = 1
n = dim(y)[1]
# Tm
# colnames(df_wsc)
covariate_scelte = c(
# "AQ_pm10",
# "Altitude",
# ,"WE_temp_2m"
# ,"WE_wind_speed_10m_mean"
"WE_wind_speed_10m_max"
# ,"WE_mode_wind_direction_10m"
,"WE_tot_precipitation"
# ,"WE_precipitation_t"
# ,"WE_surface_pressure"
# ,"WE_solar_radiation"
# ,"WE_rh_min"
# ,"WE_rh_mean"
# ,"WE_rh_max"
# ,"WE_wind_speed_100m_mean"
# ,"WE_wind_speed_100m_max"
# ,"WE_mode_wind_direction_100m"
,"WE_blh_layer_max"
# ,"WE_blh_layer_min"
# ,"EM_nh3_livestock_mm"
# ,"EM_nh3_agr_soils"
# ,"EM_nh3_agr_waste_burn"
# ,"EM_nh3_sum"
# ,"EM_nox_traffic"
# ,"EM_nox_sum"
# ,"EM_so2_sum"
# ,"LI_pigs"
# ,"LI_bovine"
# ,"LI_pigs_v2"
# ,"LI_bovine_v2"
# ,"LA_hvi"
# ,"LA_lvi"
# ,"LA_land_use"
# ,"day"
# ,"week"
)
p = lenght(covariate_scelte)
X_cl = array(data = 0, dim = c(n, p, Tm))
dim(X_cl)
cat("N * p * T = ",n,"*",p,"*",Tm,"\n")
for (pp in 1:p){
target = covariate_scelte[pp]
yfull=data.frame()
if (typeof(unique(df_wsc[,target][[1]])) != "character"){
for(st in stations[1:n]){
y_we_target=cbind(as.data.frame(st),t(df_wsc[which(df_wsc$IDStations==st),target]))
yfull=rbind(yfull,y_we_target)
}
rownames(yfull) = NULL
colnames(yfull)<- c("id",paste0("w", 1:(size(yfull)[2]-1)))
time_span = 1:12
nsubjects = 1:n
y_other = yfull[nsubjects,1+time_span]
mn <- apply(y_other,2,mean)
sd <- apply(y_other,2,sd)
y_other <- t(t(y_other) - mn) # timewise mean
# y_other <- t(t(y_other) - mean(y_other[[1]])) # global mean
for (t in 1:Tm){
X_cl[,pp,t] = y_other[,t]
}
}
}
## original variable case, i.e. centered wrt global mean actually
# for(i in 1:n){
# 	st = stations[i]
# 	for(t in 1:Tm){
# 		df_st = df_wsc[which(df_wsc$IDStations == st),]
# 		for (pp in 1:p){
# 			# X_cl[i,pp,t] = as.numeric(df_st[t,covariate_scelte[pp]])
# 			X_cl[i,pp,t] = df_st[t,covariate_scelte[pp]][[1]]
# 			# X_cl[i,pp,t] = as.character(df_st[t,covariate_scelte[pp]][[1]])
# 		}
# 	}
# }
titolo = "centered wrt time-wise mean"
# titolo = "centered wrt global mean"
# titolo = "original variable"
for (pp in 1:p){
yred=X_cl[,pp,]
target = covariate_scelte[pp]
save_plot=F
folder = "./different means/"
if (save_plot==T) { pdf(file=paste0(folder,target,titolo,".pdf"),height = 5.7,width = 11)}
par(mar=c(2,2,2,1))
col_idx = 1
for(i in ranked_indices){
if(i==ranked_indices[1]){
plot(1:size(yred)[2],yred[i,],col=cols[col_idx],
# ylim=extrema(as.matrix(yred[,-c(1)])),
ylim=extrema(as.matrix(yred)),
main=paste0(covariate_scelte[pp]," - ",titolo),
type='l',xlab='weeks',ylab='pm10')
}
else{
lines(1:size(yred)[2],yred[i,],col=cols[col_idx])
}
col_idx = col_idx+1
}
if (save_plot==T) {dev.off()}
}
colnames(X_cl) = covariate_scelte
head(X_cl)
y
a_sigma  = 0.01; b_sigma = 0.01
# a_tau    = 2.1; b_tau   = 0.9
# a_tau    = 1.7; b_tau   = 0.4
a_tau    = 1.9; b_tau   = 0.4
# a_lambda = 0.1; b_lambda = 0.1
a_lambda = 1.9; b_lambda = 0.4
module_JDRPM <- juliaImport(juliaCall("include", module))
out = module_JDRPM$MCMC_fit(
Y=as.matrix(y),
sp_coords = s_std,
M_dp = 1,
initial_partition = NA,
Xlk_covariates = NA,
Xcl_covariates = NA,
starting_alpha = 0.5,
unit_specific_alpha = FALSE,
time_specific_alpha = TRUE,
update_alpha = TRUE,
include_eta1 = TRUE,
include_phi1 = T,
update_eta1 = T, # the not so useful parameter
update_phi1 = T,
sig2h_priors = c(a_sigma,b_sigma),
eta1_priors = c(eta1_scale,sig_mh_eta1),
# beta_priors = c(rep(1,p),2),
beta_priors = NA,
tau2_priors = c(a_tau,b_tau),
phi0_priors = c(m0_phi0,s20_phi0),
phi1_priors = sig_mh_phi1,
lambda2_priors = c(a_lambda,b_lambda),
alpha_priors = c(a_alpha,b_alpha),
######## space
spatial_cohesion_idx = spatial_cohesion,
sp_params = list(c(mu0,mu0),k0,v0,matrix(c(L0,0.0,0.0,L0),nrow=2)),
######## likelihood covariates
# Xlk_covariates = X_lk, beta_priors = c(rep(0,p),1),
# Xlk_covariates = NA, beta_priors = NA,
# Xlk_covariates = X_lk, beta_priors = c(rep(0,p),1),
# beta_update_threshold = nburn/3,
######## clustering covariates
covariate_similarity_idx = 4,
# cv_params = list(0,1,4.5,0.8),
cv_params = list(0,1,
# 7.5,2,
7.5,2,
7.5,2,
7.5,2
# 4.5,1.4,
# 4.5,1.4,
# 4.5,1.4
),
# covariate_similarity_idx = 1,
# cv_params = list(1),
cv_weight = 0.3,
Xcl_covariates = X_cl,
# covariate_similarity_idx = 1,
# cv_params = list(1),
# Xcl_covariates = X_cl,
# spatial_cohesion_idx = 1,
# sp_params = list(0.1),
# covariate_similarity_idx = NA,
# draws = niter,burnin = nburn, thin = nthin,
draws = 100,burnin = 0, thin = 1,
# draws = 40000,burnin = 30000, thin = 5,
logging = F,
seed = 114.0,
simple_return = FALSE,
verbose = T,
perform_diagnostics = (niter>1000)
)
a_sigma  = 0.01; b_sigma = 0.01
# a_tau    = 2.1; b_tau   = 0.9
# a_tau    = 1.7; b_tau   = 0.4
a_tau    = 1.9; b_tau   = 0.4
# a_lambda = 0.1; b_lambda = 0.1
a_lambda = 1.9; b_lambda = 0.4
# module_JDRPM <- juliaImport(juliaCall("include", module))
out = module_JDRPM$MCMC_fit(
Y=as.matrix(y),
sp_coords = s_std,
M_dp = 1,
initial_partition = NA,
Xlk_covariates = NA,
Xcl_covariates = NA,
starting_alpha = 0.5,
unit_specific_alpha = FALSE,
time_specific_alpha = TRUE,
update_alpha = TRUE,
include_eta1 = TRUE,
include_phi1 = T,
update_eta1 = T, # the not so useful parameter
update_phi1 = T,
sig2h_priors = c(a_sigma,b_sigma),
eta1_priors = c(eta1_scale,sig_mh_eta1),
# beta_priors = c(rep(1,p),2),
beta_priors = NA,
tau2_priors = c(a_tau,b_tau),
phi0_priors = c(m0_phi0,s20_phi0),
phi1_priors = sig_mh_phi1,
lambda2_priors = c(a_lambda,b_lambda),
alpha_priors = c(a_alpha,b_alpha),
######## space
spatial_cohesion_idx = spatial_cohesion,
sp_params = list(c(mu0,mu0),k0,v0,matrix(c(L0,0.0,0.0,L0),nrow=2)),
######## likelihood covariates
# Xlk_covariates = X_lk, beta_priors = c(rep(0,p),1),
# Xlk_covariates = NA, beta_priors = NA,
# Xlk_covariates = X_lk, beta_priors = c(rep(0,p),1),
# beta_update_threshold = nburn/3,
######## clustering covariates
covariate_similarity_idx = 4,
# cv_params = list(0,1,4.5,0.8),
cv_params = list(0,1,
# 7.5,2,
7.5,2,
7.5,2,
7.5,2
# 4.5,1.4,
# 4.5,1.4,
# 4.5,1.4
),
# covariate_similarity_idx = 1,
# cv_params = list(1),
cv_weight = 0.3,
Xcl_covariates = X_cl,
# covariate_similarity_idx = 1,
# cv_params = list(1),
# Xcl_covariates = X_cl,
# spatial_cohesion_idx = 1,
# sp_params = list(0.1),
# covariate_similarity_idx = NA,
# draws = niter,burnin = nburn, thin = nthin,
draws = 100,burnin = 0, thin = 1,
# draws = 40000,burnin = 30000, thin = 5,
logging = F,
seed = 114.0,
simple_return = FALSE,
verbose = T,
perform_diagnostics = (niter>1000)
)
niter>1000
a_sigma  = 0.01; b_sigma = 0.01
# a_tau    = 2.1; b_tau   = 0.9
# a_tau    = 1.7; b_tau   = 0.4
a_tau    = 1.9; b_tau   = 0.4
# a_lambda = 0.1; b_lambda = 0.1
a_lambda = 1.9; b_lambda = 0.4
# module_JDRPM <- juliaImport(juliaCall("include", module))
out = module_JDRPM$MCMC_fit(
Y=as.matrix(y),
sp_coords = s_std,
M_dp = 1,
initial_partition = NA,
Xlk_covariates = NA,
Xcl_covariates = NA,
starting_alpha = 0.5,
unit_specific_alpha = FALSE,
time_specific_alpha = TRUE,
update_alpha = TRUE,
include_eta1 = TRUE,
include_phi1 = T,
update_eta1 = T, # the not so useful parameter
update_phi1 = T,
sig2h_priors = c(a_sigma,b_sigma),
eta1_priors = c(eta1_scale,sig_mh_eta1),
# beta_priors = c(rep(1,p),2),
beta_priors = NA,
tau2_priors = c(a_tau,b_tau),
phi0_priors = c(m0_phi0,s20_phi0),
phi1_priors = sig_mh_phi1,
lambda2_priors = c(a_lambda,b_lambda),
alpha_priors = c(a_alpha,b_alpha),
######## space
spatial_cohesion_idx = spatial_cohesion,
sp_params = list(c(mu0,mu0),k0,v0,matrix(c(L0,0.0,0.0,L0),nrow=2)),
######## likelihood covariates
# Xlk_covariates = X_lk, beta_priors = c(rep(0,p),1),
# Xlk_covariates = NA, beta_priors = NA,
# Xlk_covariates = X_lk, beta_priors = c(rep(0,p),1),
# beta_update_threshold = nburn/3,
######## clustering covariates
covariate_similarity_idx = 4,
# cv_params = list(0,1,4.5,0.8),
cv_params = list(0,1,
# 7.5,2,
7.5,2,
7.5,2,
7.5,2
# 4.5,1.4,
# 4.5,1.4,
# 4.5,1.4
),
# covariate_similarity_idx = 1,
# cv_params = list(1),
cv_weight = 0.3,
Xcl_covariates = X_cl,
# covariate_similarity_idx = 1,
# cv_params = list(1),
# Xcl_covariates = X_cl,
# spatial_cohesion_idx = 1,
# sp_params = list(0.1),
# covariate_similarity_idx = NA,
draws = niter,burnin = nburn, thin = nthin,
# draws = 100,burnin = 0, thin = 1,
# draws = 40000,burnin = 30000, thin = 5,
logging = F,
seed = 114.0,
simple_return = FALSE,
verbose = T,
perform_diagnostics = (niter>1000)
)
