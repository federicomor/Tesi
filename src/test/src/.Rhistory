alphaPriors=rbind(c(1,1)), # if time_specific_alpha == TRUE
# alphaPriors=matrix(rep(c(1,1),105),105,2), # if unit_specific_alpha == TRUE
# alphaPriors=matrix(rep(c(1,1),105),105,2), # if both the above are TRUE
simpleModel = 0,
theta_tau2 = c(0, 2), # only used if simpleModel=1
# SpatialCohesion=3, # auxiliary similarity
SpatialCohesion=4, # double dipper similarity, default one
# cParms=c(0, 1, 2, 1), # default one
cParms=c(0, 1, 5, 1), # author suggestion/used one (with 5)
# mh=c(0.5,1,0.1, 0.1, 0.1), # default one
mh=c(0.1,0.1,0.7, 0.1, 0.1), # with a bit of author suggestion/used one
verbose=TRUE,
# draws=1100,burn=100,thin=1) # quick one
# draws=31000,burn=1000,thin=1) # for trace plot analysis
# draws=8000,burn=3000,thin=5) # a bit more serious seriou one
# draws=10000,burn=2000,thin=8) # more serious one
draws=niter,burn=nburn,thin=nthin) # adaptable one
tempo_fine <- Sys.time()
differenza_tempo <- tempo_fine - tempo_inizio
cat(crayon::cyan("Fit took:\n"))
print(round(differenza_tempo,digits = 4))
cat(crayon::blue("That was for fitting",max(time_span),"time steps.\nSo for fitting all 53 weeks the expected time with these parameters will be:\n"))
print(round(differenza_tempo/max(time_span)*53,digits=4))
cat(crayon::red("\nLPML =",drpm1$lpml, "\nWAIC =",drpm1$waic))
devtools::load_all("../../drpm/")
# niter=3000; nburn=1000; nthin=2
niter=120; nburn=1; nthin=1
# niter=60000; nburn=20000; nthin=40 # original
# niter=100000; nburn=60000; nthin=40 # new one for more data
nout <- (niter-nburn)/nthin
cat(nout,"valid iterations\n")
# niter=3000; nburn=1000; nthin=2
niter=12; nburn=1; nthin=1
# niter=60000; nburn=20000; nthin=40 # original
# niter=100000; nburn=60000; nthin=40 # new one for more data
nout <- (niter-nburn)/nthin
cat(nout,"valid iterations\n")
# seed_choice = round(runif(1,0,1000))
# set.seed(seed_choice)
cat(paste0("seed ",seed_choice,"\n==========================\n",date(),"\n\n"))
tempo_inizio <- Sys.time()
drpm1 <- drpm_fit(y=y_fit,
s_coords = std_sites,
M=1,
initial_partition = NULL,
starting_alpha = 0.5,
unit_specific_alpha = FALSE,
# time_specific_alpha = TRUE, # meaning a bit ambiguos
# Ok after experimenting it means that:
# - if true we let alpha be a param that changes over time.
#	At time 1 we have a chain with some behaviour,
#	at time 2 another chain with another behaviour, ecc
# - if false we instead fix alpha, ie all chains of all times
#	will be the same, as they refer to the same parameter estimation
# The authors in their tests set it to false, ie the fixed alpha
alpha_0=FALSE, # modello temporale, questa deve sempre essere falsa
# parameters from the drpm models comparison:
# case E0P1A1
eta1_0=FALSE,
phi1_0=TRUE,
time_specific_alpha = TRUE,
# modelPriors=c(0,100^2,1,1,1,1), # original default one
modelPriors=c(0,100,10,5,5,2,2,1), # author suggestion/used one
# così con 1,1 è una uniforme
alphaPriors=rbind(c(1,1)), # if time_specific_alpha == TRUE
# alphaPriors=matrix(rep(c(1,1),105),105,2), # if unit_specific_alpha == TRUE
# alphaPriors=matrix(rep(c(1,1),105),105,2), # if both the above are TRUE
simpleModel = 0,
theta_tau2 = c(0, 2), # only used if simpleModel=1
# SpatialCohesion=3, # auxiliary similarity
SpatialCohesion=4, # double dipper similarity, default one
# cParms=c(0, 1, 2, 1), # default one
cParms=c(0, 1, 5, 1), # author suggestion/used one (with 5)
# mh=c(0.5,1,0.1, 0.1, 0.1), # default one
mh=c(0.1,0.1,0.7, 0.1, 0.1), # with a bit of author suggestion/used one
verbose=TRUE,
# draws=1100,burn=100,thin=1) # quick one
# draws=31000,burn=1000,thin=1) # for trace plot analysis
# draws=8000,burn=3000,thin=5) # a bit more serious seriou one
# draws=10000,burn=2000,thin=8) # more serious one
draws=niter,burn=nburn,thin=nthin) # adaptable one
tempo_fine <- Sys.time()
differenza_tempo <- tempo_fine - tempo_inizio
cat(crayon::cyan("Fit took:\n"))
print(round(differenza_tempo,digits = 4))
cat(crayon::blue("That was for fitting",max(time_span),"time steps.\nSo for fitting all 53 weeks the expected time with these parameters will be:\n"))
print(round(differenza_tempo/max(time_span)*53,digits=4))
cat(crayon::red("\nLPML =",drpm1$lpml, "\nWAIC =",drpm1$waic))
devtools::load_all("../../drpm/")
# niter=3000; nburn=1000; nthin=2
niter=12; nburn=1; nthin=1
# niter=60000; nburn=20000; nthin=40 # original
# niter=100000; nburn=60000; nthin=40 # new one for more data
nout <- (niter-nburn)/nthin
cat(nout,"valid iterations\n")
# seed_choice = round(runif(1,0,1000))
# set.seed(seed_choice)
cat(paste0("seed ",seed_choice,"\n==========================\n",date(),"\n\n"))
tempo_inizio <- Sys.time()
drpm1 <- drpm_fit(y=y_fit,
s_coords = std_sites,
M=1,
initial_partition = NULL,
starting_alpha = 0.5,
unit_specific_alpha = FALSE,
# time_specific_alpha = TRUE, # meaning a bit ambiguos
# Ok after experimenting it means that:
# - if true we let alpha be a param that changes over time.
#	At time 1 we have a chain with some behaviour,
#	at time 2 another chain with another behaviour, ecc
# - if false we instead fix alpha, ie all chains of all times
#	will be the same, as they refer to the same parameter estimation
# The authors in their tests set it to false, ie the fixed alpha
alpha_0=FALSE, # modello temporale, questa deve sempre essere falsa
# parameters from the drpm models comparison:
# case E0P1A1
eta1_0=FALSE,
phi1_0=TRUE,
time_specific_alpha = TRUE,
# modelPriors=c(0,100^2,1,1,1,1), # original default one
modelPriors=c(0,100,10,5,5,2,2,1), # author suggestion/used one
# così con 1,1 è una uniforme
alphaPriors=rbind(c(1,1)), # if time_specific_alpha == TRUE
# alphaPriors=matrix(rep(c(1,1),105),105,2), # if unit_specific_alpha == TRUE
# alphaPriors=matrix(rep(c(1,1),105),105,2), # if both the above are TRUE
simpleModel = 0,
theta_tau2 = c(0, 2), # only used if simpleModel=1
# SpatialCohesion=3, # auxiliary similarity
SpatialCohesion=4, # double dipper similarity, default one
# cParms=c(0, 1, 2, 1), # default one
cParms=c(0, 1, 5, 1), # author suggestion/used one (with 5)
# mh=c(0.5,1,0.1, 0.1, 0.1), # default one
mh=c(0.1,0.1,0.7, 0.1, 0.1), # with a bit of author suggestion/used one
verbose=TRUE,
# draws=1100,burn=100,thin=1) # quick one
# draws=31000,burn=1000,thin=1) # for trace plot analysis
# draws=8000,burn=3000,thin=5) # a bit more serious seriou one
# draws=10000,burn=2000,thin=8) # more serious one
draws=niter,burn=nburn,thin=nthin) # adaptable one
tempo_fine <- Sys.time()
differenza_tempo <- tempo_fine - tempo_inizio
cat(crayon::cyan("Fit took:\n"))
print(round(differenza_tempo,digits = 4))
cat(crayon::blue("That was for fitting",max(time_span),"time steps.\nSo for fitting all 53 weeks the expected time with these parameters will be:\n"))
print(round(differenza_tempo/max(time_span)*53,digits=4))
cat(crayon::red("\nLPML =",drpm1$lpml, "\nWAIC =",drpm1$waic))
devtools::load_all("../../drpm/")
devtools::load_all("../../drpm/")
# niter=3000; nburn=1000; nthin=2
niter=12; nburn=1; nthin=1
# niter=60000; nburn=20000; nthin=40 # original
# niter=100000; nburn=60000; nthin=40 # new one for more data
nout <- (niter-nburn)/nthin
cat(nout,"valid iterations\n")
time_span = 40:50 # low time span for quick testing, real one will be 1:53
### authors suggested to/did scale the spatial locations and also centered the observations
y_fit = y[,1+time_span]
y_fit
### and for the scaling of spatial locations
std_sites = data.frame(
longitude = unique(df_wsc$Longitude),
latitude = unique(df_wsc$Latitude))
plot(sites)
plot(std_sites)
# niter=3000; nburn=1000; nthin=2
niter=1200; nburn=1; nthin=1
# niter=60000; nburn=20000; nthin=40 # original
# niter=100000; nburn=60000; nthin=40 # new one for more data
nout <- (niter-nburn)/nthin
cat(nout,"valid iterations\n")
# seed_choice = round(runif(1,0,1000))
# set.seed(seed_choice)
cat(paste0("seed ",seed_choice,"\n==========================\n",date(),"\n\n"))
tempo_inizio <- Sys.time()
drpm1 <- drpm_fit(y=y_fit,
s_coords = std_sites,
M=1,
initial_partition = NULL,
starting_alpha = 0.5,
unit_specific_alpha = FALSE,
# time_specific_alpha = TRUE, # meaning a bit ambiguos
# Ok after experimenting it means that:
# - if true we let alpha be a param that changes over time.
#	At time 1 we have a chain with some behaviour,
#	at time 2 another chain with another behaviour, ecc
# - if false we instead fix alpha, ie all chains of all times
#	will be the same, as they refer to the same parameter estimation
# The authors in their tests set it to false, ie the fixed alpha
alpha_0=FALSE, # modello temporale, questa deve sempre essere falsa
# parameters from the drpm models comparison:
# case E0P1A1
eta1_0=FALSE,
phi1_0=TRUE,
time_specific_alpha = TRUE,
# modelPriors=c(0,100^2,1,1,1,1), # original default one
modelPriors=c(0,100,10,5,5,2,2,1), # author suggestion/used one
# così con 1,1 è una uniforme
alphaPriors=rbind(c(1,1)), # if time_specific_alpha == TRUE
# alphaPriors=matrix(rep(c(1,1),105),105,2), # if unit_specific_alpha == TRUE
# alphaPriors=matrix(rep(c(1,1),105),105,2), # if both the above are TRUE
simpleModel = 0,
theta_tau2 = c(0, 2), # only used if simpleModel=1
# SpatialCohesion=3, # auxiliary similarity
SpatialCohesion=4, # double dipper similarity, default one
# cParms=c(0, 1, 2, 1), # default one
cParms=c(0, 1, 5, 1), # author suggestion/used one (with 5)
# mh=c(0.5,1,0.1, 0.1, 0.1), # default one
mh=c(0.1,0.1,0.7, 0.1, 0.1), # with a bit of author suggestion/used one
verbose=TRUE,
# draws=1100,burn=100,thin=1) # quick one
# draws=31000,burn=1000,thin=1) # for trace plot analysis
# draws=8000,burn=3000,thin=5) # a bit more serious seriou one
# draws=10000,burn=2000,thin=8) # more serious one
draws=niter,burn=nburn,thin=nthin) # adaptable one
tempo_fine <- Sys.time()
differenza_tempo <- tempo_fine - tempo_inizio
cat(crayon::cyan("Fit took:\n"))
print(round(differenza_tempo,digits = 4))
cat(crayon::blue("That was for fitting",max(time_span),"time steps.\nSo for fitting all 53 weeks the expected time with these parameters will be:\n"))
print(round(differenza_tempo/max(time_span)*53,digits=4))
cat(crayon::red("\nLPML =",drpm1$lpml, "\nWAIC =",drpm1$waic))
model_name = "model_with_my_code_update"
# loss = binder(a=1) # plus maxNClusters = 6 or similar
loss = "VI"
# loss = "VI.lb" # generally not recomended, lo dicono gli autori di salso
# loss = "NVI"
# loss = "NID"
df_cluster = data.frame(Longitude=c(),Latitude=c(),values=c(),clusters=c(),Time=c())
for(time in time_span){
salso_out <- salso(t(drpm1$Si[time,,]),
loss=binder(a=1),
# loss="VI",
# loss="VI.lb",
maxNClusters = 6
)
df_temp = data.frame(
Longitude = sites$longitude,
Latitude = sites$latitude,
clusters = salso_out[1:105]
)
df_temp$Time = rep(time,dim(df_temp)[1])
df_cluster = rbind(df_cluster,df_temp)
# clusters log
clusters_now = df_temp$clusters
# n_clusters = max(clusters_now)
n_clusters = unique(clusters_now)
ycurrent = y[,paste0("w",time)]
cat(crayon::red("Time",time,"- #clusters =",length(unique(clusters_now)),"\n"))
# for (cl in n_clusters){
# cat("Cluster",cl,"- size",length(ycurrent[which(clusters_now==cl)]),
# "- mean",mean(ycurrent[which(clusters_now==cl)]),"\n")
# }
}
time_span
df_cluster = data.frame(Longitude=c(),Latitude=c(),values=c(),clusters=c(),Time=c())
for(time in time_span){
salso_out <- salso(t(drpm1$Si[time,,]),
loss=binder(a=1),
# loss="VI",
# loss="VI.lb",
maxNClusters = 6
)
df_temp = data.frame(
Longitude = sites$longitude,
Latitude = sites$latitude,
clusters = salso_out[1:105]
)
df_temp$Time = rep(time,dim(df_temp)[1])
df_cluster = rbind(df_cluster,df_temp)
# clusters log
clusters_now = df_temp$clusters
# n_clusters = max(clusters_now)
n_clusters = unique(clusters_now)
ycurrent = y[,paste0("w",time)]
cat(crayon::red("Time",time,"- #clusters =",length(unique(clusters_now)),"\n"))
# for (cl in n_clusters){
# cat("Cluster",cl,"- size",length(ycurrent[which(clusters_now==cl)]),
# "- mean",mean(ycurrent[which(clusters_now==cl)]),"\n")
# }
}
drpm1$Si
size(drpm1$Si)
df_cluster = data.frame(Longitude=c(),Latitude=c(),values=c(),clusters=c(),Time=c())
for(time in time_span){
salso_out <- salso(t(drpm1$Si[time-39,,]),
loss=binder(a=1),
# loss="VI",
# loss="VI.lb",
maxNClusters = 6
)
df_temp = data.frame(
Longitude = sites$longitude,
Latitude = sites$latitude,
clusters = salso_out[1:105]
)
df_temp$Time = rep(time,dim(df_temp)[1])
df_cluster = rbind(df_cluster,df_temp)
# clusters log
clusters_now = df_temp$clusters
# n_clusters = max(clusters_now)
n_clusters = unique(clusters_now)
ycurrent = y[,paste0("w",time)]
cat(crayon::red("Time",time,"- #clusters =",length(unique(clusters_now)),"\n"))
# for (cl in n_clusters){
# cat("Cluster",cl,"- size",length(ycurrent[which(clusters_now==cl)]),
# "- mean",mean(ycurrent[which(clusters_now==cl)]),"\n")
# }
}
min(time_span)
df_cluster = data.frame(Longitude=c(),Latitude=c(),values=c(),clusters=c(),Time=c())
for(time in time_span){
salso_out <- salso(t(drpm1$Si[time-(min(time_span)-1),,]),
loss=binder(a=1),
# loss="VI",
# loss="VI.lb",
maxNClusters = 6
)
df_temp = data.frame(
Longitude = sites$longitude,
Latitude = sites$latitude,
clusters = salso_out[1:105]
)
df_temp$Time = rep(time,dim(df_temp)[1])
df_cluster = rbind(df_cluster,df_temp)
# clusters log
clusters_now = df_temp$clusters
# n_clusters = max(clusters_now)
n_clusters = unique(clusters_now)
ycurrent = y[,paste0("w",time)]
cat(crayon::red("Time",time,"- #clusters =",length(unique(clusters_now)),"\n"))
# for (cl in n_clusters){
# cat("Cluster",cl,"- size",length(ycurrent[which(clusters_now==cl)]),
# "- mean",mean(ycurrent[which(clusters_now==cl)]),"\n")
# }
}
library(mclust)
##########################
FIT = drpm1 # your fit
LEN = max(time_span)
##########################
# build the ARI matrix
ARImats <- matrix(NA, nrow=LEN, ncol=LEN)
rho_ARI <- list()
for(k in 1:LEN){
rho_ARI[[k]] <- salso(t(FIT$Si[k,,]),
loss=binder(a=1),
# loss="VI",
# loss="VI.lb",
maxNClusters = 6
) # adjust with your fit $Si dimension
}
library(mclust)
##########################
FIT = drpm1 # your fit
LEN = max(time_span)
##########################
# build the ARI matrix
ARImats <- matrix(NA, nrow=LEN, ncol=LEN)
rho_ARI <- list()
for(k in 1:LEN){
rho_ARI[[k]] <- salso(t(FIT$Si[k-(min(time_span)+1),,]),
loss=binder(a=1),
# loss="VI",
# loss="VI.lb",
maxNClusters = 6
) # adjust with your fit $Si dimension
}
library(mclust)
##########################
FIT = drpm1 # your fit
LEN = max(time_span)
##########################
# build the ARI matrix
ARImats <- matrix(NA, nrow=LEN, ncol=LEN)
rho_ARI <- list()
for(k in 1:LEN){
rho_ARI[[k]] <- salso(t(FIT$Si[k,,]),
loss=binder(a=1),
# loss="VI",
# loss="VI.lb",
maxNClusters = 6
) # adjust with your fit $Si dimension
}
rho_ARI[[k-(min(time_span)+1)]] <- salso(t(FIT$Si[k-(min(time_span)+1),,]),
loss=binder(a=1),
# loss="VI",
# loss="VI.lb",
maxNClusters = 6
) # adjust with your fit $Si dimension
# build the ARI matrix
ARImats <- matrix(NA, nrow=LEN, ncol=LEN)
range(time_span)
##########################
FIT = drpm1 # your fit
LEN = max(time_span)-min(time_span)
# build the ARI matrix
ARImats <- matrix(NA, nrow=LEN, ncol=LEN)
rho_ARI <- list()
for(k in time_span){
rho_ARI[[k-(min(time_span)+1)]] <- salso(t(FIT$Si[k-(min(time_span)+1),,]),
loss=binder(a=1),
# loss="VI",
# loss="VI.lb",
maxNClusters = 6
) # adjust with your fit $Si dimension
}
time_span = 1:10 # low time span for quick testing, real one will be 1:53
### authors suggested to/did scale the spatial locations and also centered the observations
y_fit = y[,1+time_span]
y_fit
### and for the scaling of spatial locations
std_sites = data.frame(
longitude = unique(df_wsc$Longitude),
latitude = unique(df_wsc$Latitude))
plot(sites)
plot(std_sites)
df_cluster = data.frame(Longitude=c(),Latitude=c(),values=c(),clusters=c(),Time=c())
for(time in time_span){
salso_out <- salso(t(drpm1$Si[time-(min(time_span)-1),,]),
loss=binder(a=1),
# loss="VI",
# loss="VI.lb",
maxNClusters = 6
)
df_temp = data.frame(
Longitude = sites$longitude,
Latitude = sites$latitude,
clusters = salso_out[1:105]
)
df_temp$Time = rep(time,dim(df_temp)[1])
df_cluster = rbind(df_cluster,df_temp)
# clusters log
clusters_now = df_temp$clusters
# n_clusters = max(clusters_now)
n_clusters = unique(clusters_now)
ycurrent = y[,paste0("w",time)]
cat(crayon::red("Time",time,"- #clusters =",length(unique(clusters_now)),"\n"))
# for (cl in n_clusters){
# cat("Cluster",cl,"- size",length(ycurrent[which(clusters_now==cl)]),
# "- mean",mean(ycurrent[which(clusters_now==cl)]),"\n")
# }
}
library(mclust)
##########################
FIT = drpm1 # your fit
LEN = max(time_span)
##########################
# build the ARI matrix
ARImats <- matrix(NA, nrow=LEN, ncol=LEN)
rho_ARI <- list()
for(k in 1:LEN){
rho_ARI[[k]] <- salso(t(FIT$Si[k,,]),
loss=binder(a=1),
# loss="VI",
# loss="VI.lb",
maxNClusters = 6
) # adjust with your fit $Si dimension
}
for(k in 1: LEN){
for(kk in 1: LEN){
ARImats[k,kk] <- adjustedRandIndex(rho_ARI[[k]], rho_ARI[[kk]])
}
}
hist(ARImats)
# pdf(paste0("./figures/Federico/LaggedARI_",model_name,".pdf"), height=8, width=10)
ncols_ari = 100
if (min(ARImats)<0){
cols_ARI = colora(ncols_ari,79,0)
brks = seq(floor(min(ARImats)),1,length.out=ncols_ari+1)
} else {
cols_ARI = colora(ncols_ari,56,0)
cols_ARI = rev(cols_ARI) # must be ordered from cold to warm
brks = seq(0,1,length.out=ncols_ari+1)
}
# or see ?designer.colors for colors
library(fields)
image.plot(ARImats,
main=paste0("Lagged ARI values - model ",model_name),axes=FALSE,col=cols_ARI,
breaks=brks)
mtext(text=c(paste("",1:LEN)), side=2, line=0.3,at=seq(0,1,length=LEN), las=1, cex=0.8)
mtext(text=c(paste("",1:LEN)), side=1, line=0.3,at=seq(0,1,length=LEN), las=2, cex=0.8)
# dev.off()
# cols chosen previously
clusters_old = NULL
for(time in time_span){
cat(crayon::red("Time",time,"\n"))
df_cluster_cut = df_cluster[df_cluster$Time==time,]
clusters_now = df_cluster_cut$clusters
clusters_now = mode_correct_clusters(clusters_old,clusters_now,very_verbose = 0)
df_cluster_cut$clusters = clusters_now
q = get_graph_plot(df_cluster_cut)
print(q)
clusters_old = clusters_now
}
clusters_old = NULL
for(time in time_span[1:10]){
cat(crayon::red("Time",time,"\n"))
df_cluster_cut = df_cluster[df_cluster$Time==time,]
clusters_now = df_cluster_cut$clusters
####### no mode correct now
# clusters_now = mode_correct_clusters(clusters_old,clusters_now,very_verbose = 0)
# se fai heat plot non serve fare la mode correct
# perché la heat plot la usi per vedere anche i valori di pm10, non la coerenza temporale
# nei gruppi, che con la heat coloration si perde come visibilità (non so se è chiaro)
df_cluster_cut$clusters = clusters_now
# meglio l'idea 1
cols = color_correct_clusters(df_cluster_cut,idea=1,verbose=0)
# q = get_graph_plot(df_cluster_cut,cols)
# print(q)
p = plot_graph_and_hist(df_cluster_cut,cols)
clusters_old = clusters_now
}
